# NVIDIA optimization journal

This journal tracks measured NVIDIA backend experiments so we can iterate quickly without repeating dead ends.

## Benchmark protocol

### Kernel benchmark (single backend path)

```bash
cargo run --release -- --bench --bench-kind kernel --backend nvidia --nvidia-devices 0 --bench-secs 10 --bench-rounds 3 --ui plain --bench-output <report.json>
```

### Backend benchmark (persistent worker path)

```bash
cargo run --release -- --bench --bench-kind backend --backend nvidia --nvidia-devices 0 --bench-secs 10 --bench-rounds 3 --ui plain --bench-output <report.json>
```

### Acceptance gate

- Hardware target: RTX 3080 (10 GiB), unless explicitly noted.
- Keep only changes that improve multi-round counted H/s without increasing correctness/runtime risk (OOM, crashes, unstable cancel/fence behavior).
- Variance is expected from clocks and thermals; prioritize repeated 3-round results over single samples.

## Baseline

- Initial native CUDA backend baseline (`2b5ed78`): `0.065 H/s`.
- Early pre-rewrite tuned state (pre-`35190c1`, probe + backoff + regcap): up to `0.128 H/s`.
- Current validated profile for future passes (2026-02-14, RTX 3080):
  - State: `working tree` (post-pass)
  - Best observed 3-round averages: kernel `1.600 H/s`, backend `1.532 H/s`
  - Kernel model: cooperative per-lane execution (`32` threads/lane block), full-warp compression mapping (`8` states x `4` threads/state)
  - Default launch depth: `--nvidia-hashes-per-launch-per-lane 2` (set `1` for finer preemption)
  - Fused target-check path remains optional (`--nvidia-fused-target-check`) and defaults OFF on this profile

## Attempted changes

Each row is an explicit attempt ID. IDs are chronological and map 1:1 to the appendix in `## Full attempt history (newest -> oldest)`.

| Attempt | Date | Change | Outcome |
| --- | --- | --- | --- |
| A52 | 2026-02-17 | Re-test in-kernel cancel checkpoint cadence: `CANCEL_CHECK_BLOCK_INTERVAL` `64 -> 96` | Reverted (backend A/B regressed `-2.45%`; late-hash share unchanged) |
| A51 | 2026-02-17 | Seed prehash batching in `build_seed_blocks_kernel`: combine fixed Argon2 fields into one `blake2b_update` and collapse terminal zero updates (`4+4 -> 8`) | Reverted (backend A/B was only `+0.34%` and below keep gate; kernel remained flat) |
| A50 | 2026-02-17 | Re-test evaluate-kernel launch geometry: `EVAL_KERNEL_THREADS` `64 -> 32` (seed kernel unchanged) | Reverted (quick A/B was near-noise `+0.38%`, but longer 4-pair interleaved rerun regressed `-1.11%`; kernel remained flat) |
| A49 | 2026-02-17 | Eval hash-input packing shortcut: replace per-word LE stores in `blake2b_long_32_from_words` with direct raw-block byte hashing via `blake2b_long_32_from_block` | Reverted (initial 2-pair backend A/B showed `+2.95%`, but extended 4-pair interleaved rerun showed `-3.83%`; kernel remained flat) |
| A48 | 2026-02-17 | Non-fused evaluate pipeline change: launch `evaluate_hashes_kernel` before host `completed_iters` D2H by bounding evaluate on device-side completion state | Reverted (no measured gain; backend runs were in thermally degraded window and did not exceed kept baseline) |
| A47 | 2026-02-17 | Seed temporary-buffer trimming experiment (in-place `blake2b_hash` chaining + direct `h0` placement into seed buffer) | Reverted (no measured gain; resource usage unchanged for main kernels and backend did not improve in repeated runs) |
| A46 | 2026-02-17 | Split fill kernel into dedicated non-fused/fused entrypoints, reduce seed-kernel stack staging (`blake2b_long_1024_words` direct word emit), and widen regcap frontier with architecture-aware autotune sets (schema `7 -> 8`) | Kept (fixed `rreg=208` backend `+0.37%`, best re-probed caps `rreg=192/144` at `+0.54%` vs preopt baseline, kernel parity at `1.200 H/s`; generated code improved on hot path: non-fused fill `REG 156-157, STACK 352 -> REG 90-94, STACK 0`; seed stack reduced `1888 -> 800`) |
| A45 | 2026-02-14 | Seed/eval launch-size probe: `SEED_KERNEL_THREADS/EVAL_KERNEL_THREADS` `64 -> 32` (host + CUDA constants) | Reverted (results were inconsistent/inconclusive under host-load variance; no reliable improvement over kept `64/64`) |
| A44 | 2026-02-14 | Re-test cancel-check interval `64 -> 96` under cleaner A/B runs (`20s` rounds, interleaved `96/64/96/64`) | Reverted (no stable gain; controlled 20s A/B slightly favored `64`) |
| A43 | 2026-02-14 | Deadline-tail batch-size clamp using per-assignment hash-time EMA (`hashes_per_batch` capped by remaining `stop_at` budget) | Reverted (reduced late work but clear throughput regression) |
| A42 | 2026-02-14 | Inner-loop shared `prev_block` cache rewrite in `argon2id_fill_kernel` (`compress_block_coop` extended with `next_rhs`, remove per-iter shared zeroing, reuse cached `rhs` for data-dependent `rand64`) | Reverted (kernel parity but backend regression `-2.42%` to `-2.49%`) |
| A41 | 2026-02-14 | Over-reduce cancel-check frequency: `CANCEL_CHECK_BLOCK_INTERVAL` `64 -> 128` | Reverted (`-1.28%` vs baseline, and clearly below the `64` candidate) |
| A40 | 2026-02-14 | Raise in-kernel cancel checkpoint interval `CANCEL_CHECK_BLOCK_INTERVAL` `32 -> 64` to reduce control-check overhead in the Argon2 inner block loop | Kept (repeatable backend uplift `+0.95%` to `+1.28%` with unchanged `late_hash_pct=25%` and no kernel regression) |
| A39 | 2026-02-14 | Launch-depth sanity sweep with fixed `--nvidia-max-rregcount 224`: compare `--nvidia-hashes-per-launch-per-lane` `2/3/4` under the same 3-round backend benchmark | Kept depth-2 as operational default for this profile (higher static depth regressed counted H/s and/or increased late-work share) |
| A38 | 2026-02-14 | Retune adaptive-pressure dynamics: `ADAPTIVE_DEPTH_PRESSURE_CONTROL_BONUS 4 -> 2`, `ADAPTIVE_DEPTH_PRESSURE_REPLACE_BONUS 2 -> 1` (same ratio, faster effective decay) | Kept (repeatable backend uplift `+6.34%` to `+6.71%` with unchanged `late_hash_pct=25%`; no kernel regression) |
| A37 | 2026-02-14 | Idle-phase adaptive-pressure resets on assign/cancel/fence when no active/queued work | Reverted (`-0.78%`, no late-hash improvement) |
| A36 | 2026-02-14 | Immediate cancel-path CUDA interrupt on every regular `cancel` request (not only timeout interrupts) | Reverted (first run near-flat `-0.25%`, rerun `-5.31%`; extra cancel signaling added instability/regression in this environment) |
| A35 | 2026-02-14 | Adaptive launch-depth pressure accounting fix: only add replace/cancel/fence pressure when commands preempt active/queued work (idle round-boundary control no longer ratchets pressure) | Kept (small but consistent uplift in low-clock control-pressure scenarios: `+0.29%` to `+1.08%`; avoids false depth throttling after idle cancel/fence bookkeeping) |
| A34 | 2026-02-14 | NVIDIA worker adaptive launch-depth rewrite: add per-assignment hash-time EMA and deadline-headroom depth trimming near `stop_at` (no lane throttling, max depth still operator-controlled) | Kept (backend avg `+5.58%` vs prior sample and `+1.36%` vs non-adaptive control while holding `late_hash_pct=25%`; kernel throughput unchanged at `1.600 H/s`) |
| A33 | 2026-02-14 | NVIDIA policy/config surface + optional fused in-kernel target evaluation + finer in-kernel cancel checkpoints + autotune schema bump `6 -> 7` with deadline-aware counted-H/s scoring and expanded depth candidates | Kept with fused default OFF (control responsiveness improved under stale/cancel pressure and autotune now optimizes deadline-window effective work; fused path retained as experimental knob) |
| A32 | 2026-02-14 | GPU-side seed and solution evaluation pipeline (`build_seed_blocks_kernel` + `evaluate_hashes_kernel`), worker loop migrated to GPU-found nonce path, pinned lane hint across starts, autotune key/schema update (`4 -> 5`) with memory-budget bucketing + lane-capacity tier | Kept (backend uplift vs prior best `1.503 H/s` is `+1.93%`, stable 3-round kernel parity, and removes host-side hashing overhead + cache-key churn) |
| A31 | 2026-02-14 | Multi-hash-per-launch path + increase default `nvidia_hashes_per_launch_per_lane` `1 -> 2` | Kept (higher counted throughput on RTX 3080; baseline-mean `1.358` -> final `1.503` (`+10.68%`); tradeoff: late-hash share increased from `25%` to `42.86-50.00%`, keep CLI override for finer preemption) |
| A30 | 2026-02-14 | NVIDIA tuning surface expansion (`--nvidia-max-rregcount`, `--nvidia-max-lanes`, `--nvidia-dispatch-iters-per-lane`, `--nvidia-allocation-iters-per-lane`, `--nvidia-autotune-samples`), autotune schema bump `3 -> 4`, key update (`memory_budget_mib`), per-candidate multi-sample median scoring | Kept (robust autotune cache identity + lower tuning variance; no correctness/runtime regressions) |
| A29 | 2026-02-14 | Warp-utilization rewrite in `compress_block_coop` (`tid<8` phases -> full-warp cooperative state mapping) | Kept (kernel mean `+21.22%`; backend mean `+9.47%`; clear sustained uplift) |
| A28 | 2026-02-14 | Little-endian memcpy fast path for seed-word expansion + final block byte packing | Reverted (backend delta `-0.34%`, below keep gate and negative) |
| A27 | 2026-02-14 | Deadline-tail dynamic lane throttling via per-assignment hash-time EMA | Reverted (clear throughput regression; reduced late shares but hurt total H/s) |
| A26 | 2026-02-14 | True NVIDIA batch queueing (no collapse), free-VRAM-aware lane budgeting (`derive_memory_budget_mib`), autotune key/schema update (`schema=3`, include compute capability) | Kept (kernel mean `+18.29%`; backend mean `+7.29%` across all clean samples; queueing correctness + OOM resilience improved) |
| A25 | 2026-02-14 | Remove live `SEINE_BLOCK_LOOP_UNROLL` NVRTC/kernel path; keep cache compatibility (`schema=2`, `#[serde(default)] block_loop_unroll`) and unroll candidate disabled | Kept (kernel best `+1.44%`; backend best `+5.44%`; avoids forced cache-rebuild churn) |
| A24 | 2026-02-14 | Keep worker channel split + nonblocking control path; revert deadline-tail lane throttling | Kept (`+2.89%` best-vs-baseline; control enqueue no longer blocks behind long kernel batches) |
| A23 | 2026-02-14 | Split NVIDIA worker channels (`assign` vs `control`), enable true nonblocking backend calls, and initially add deadline-tail lane throttling plus loop-unroll autotune candidate | Partially reverted (tail throttling + active unroll path regressed throughput) |
| A22 | 2026-02-13 | Drop NVRTC option `--use_fast_math` from NVIDIA kernel compile flags | Reverted (`-0.70%` best-vs-baseline, below keep gate and negative) |
| A21 | 2026-02-13 | Add NVRTC PTXAS cache hint `--ptxas-options=-dlcm=cg` | Reverted (`-7.99%` best-vs-baseline, clear and stable regression) |
| A20 | 2026-02-13 | NVIDIA autotune schema bump `2 -> 3` + regcap candidate sweep `240/224/208/192/176/160/144` | Reverted (best delta `0.00%`, below `0.5%` keep gate; introduced one-time cache-rebuild outlier) |
| A19 | 2026-02-13 | Drop NVRTC option `--extra-device-vectorization` from NVIDIA kernel compile flags | Kept (`+9.05%` best-vs-baseline, `+8.41%` mean, stable across rerun) |
| A18 | 2026-02-13 | NVIDIA autotune schema bump `1 -> 2` + regcap candidate sweep `240/224/208/192/160` | Kept (`+3.44%` best-vs-baseline; first candidate outlier tied to one-time cache rebuild) |
| A17 | 2026-02-13 | Compile-time Argon2 constants via NVRTC defines (`SEINE_FIXED_M_BLOCKS`, `SEINE_FIXED_T_COST`) | Kept (new best, stable over rerun) |
| A16 | 2026-02-13 | Direct compression write-to-destination (drop `block_tmp` shared staging) | Kept (clear uplift over baseline) |
| A15 | 2026-02-13 | Remove post-store `coop_sync()` in inner block loop | Reverted (regressed vs 1.026 baseline) |
| A14 | 2026-02-13 | Keep warp-sync + drop device hash-counter + restore per-thread ref-index + remove pre-D2H stream sync | Kept (new best, stable over rerun) |
| A13 | 2026-02-13 | Warp-sync + device hash-counter removal + lane-0 ref-index broadcast | Reverted (slower than baseline) |
| A12 | 2026-02-13 | Cooperative loop unroll pragma pass | Reverted |
| A11 | 2026-02-13 | Thread-0-only ref-index mapping micro-opt | Reverted |
| A10 | 2026-02-13 | PTXAS cache hint `-dlcm=ca` | Reverted |
| A09 | 2026-02-13 | Regcap A/B: `224` vs `160` | `224` kept |
| A08 | 2026-02-13 | Lane cap sweep: `1/2/3/4` | Highest lane count kept |
| A07 | 2026-02-13 | Cooperative threads sweep: `24/32/40/48` | `32` kept |
| A06 | 2026-02-13 | Cooperative per-lane kernel rewrite | Kept |
| A05 | 2026-02-13 | VRAM touch-probe + lane backoff + regcap tuning | Kept in `35190c1` |
| A04 | 2026-02-13 | Shared-memory scratch rewrite (old kernel) | Reverted |
| A03 | 2026-02-13 | Full free-VRAM lane sizing without probe | Reverted |
| A02 | 2026-02-13 | One lane per CUDA block launch geometry | Kept |
| A01 | 2026-02-13 | Initial native CUDA backend | Baseline |

## Validation

- Repeated 3-round reruns on RTX 3080 validated best observed averages of kernel `1.600 H/s` and backend `1.532 H/s`.
- Fused in-kernel target checking remains available but defaults OFF due to measured regression on this profile.
- Full experiment artifacts are retained in `data/` and `/tmp` references listed below.

## Full attempt history (newest -> oldest)
| Attempt | Date | Commit/State | Change | Result | Outcome |
| --- | --- | --- | --- | --- | --- |
| A52 | 2026-02-17 | working tree | Cancel-check cadence retest in Argon2 block loop: `CANCEL_CHECK_BLOCK_INTERVAL` `64 -> 96` | backend A/B (`pairs=2`) `-2.45%` (`data/bench_nvidia_ab_backend_a52_20260217/summary.txt`) | Reverted (clear backend regression with no late-hash improvement; no kernel follow-up run needed) |
| A51 | 2026-02-17 | working tree | Seed prehash batching in `build_seed_blocks_kernel`: bundle fixed Argon2 parameter fields into one `blake2b_update`, keep nonce/header dynamic, and collapse zero tail updates into one 8-byte call | backend A/B (`pairs=2`) `+0.34%` (`data/bench_nvidia_ab_backend_a51_20260217/summary.txt`), kernel A/B parity `0.00%` (`data/bench_nvidia_ab_kernel_a51_20260217/summary.txt`) | Reverted (improvement was below keep threshold and not worth churn/risk) |
| A50 | 2026-02-17 | working tree | Evaluate-kernel launch-geometry retest: `EVAL_KERNEL_THREADS` `64 -> 32` (seed launch stayed `64`) | quick backend A/B (`pairs=2`) `+0.38%` (`data/bench_nvidia_ab_backend_a50_20260217/summary.txt`), kernel A/B parity `0.00%` (`data/bench_nvidia_ab_kernel_a50_20260217/summary.txt`), confirmation backend A/B (`pairs=4`) `-1.11%` (`data/bench_nvidia_ab_backend_a50b_20260217/summary.txt`) | Reverted (no durable gain; longer interleaved run showed net backend regression) |
| A49 | 2026-02-17 | working tree | Eval hash-input packing shortcut in `blake2b_long_32_from_words`: hash raw `block_words` bytes directly through `blake2b_long_32_from_block` instead of per-word/chunk LE packing | quick backend A/B (`pairs=2`) `+2.95%` (`data/bench_nvidia_ab_backend_a49_20260217/summary.txt`), confirmation backend A/B (`pairs=4`) `-3.83%` (`data/bench_nvidia_ab_backend_a49b_20260217/summary.txt`), kernel A/B parity `0.00%` (`data/bench_nvidia_ab_kernel_a49_20260217/summary.txt`) | Reverted (short-run uplift did not hold under longer interleaved run; likely measurement noise plus extra eval-path overhead) |
| A48 | 2026-02-17 | working tree | Non-fused evaluate pipeline test: launch `evaluate_hashes_kernel` immediately after fill kernel using device-side completion bounds, then copy `completed_iters` on host | backend `1.089 H/s` (`data/bench_nv_backend_evalasync_20260217.json`), kernel parity `1.200 H/s` (`data/bench_nv_kernel_evalasync_20260217.json`), same-session thermal check on kept code `1.014 H/s` (`data/bench_nv_backend_thermal_check_20260217.json`) | Reverted (no demonstrable win and session was thermally degraded, so results were non-qualifying for keep) |
| A47 | 2026-02-17 | working tree | Seed temporary-buffer trimming experiment: in-place `blake2b_hash` chaining in `blake2b_long_1024_words` and direct `h0` write into `seed_input` | backend `1.101/1.099 H/s` (`data/bench_nv_backend_postopt_seedpass_20260217.json`, `data/bench_nv_backend_postopt_seedpass_rerun_20260217.json`), kernel parity `1.200 H/s` (`data/bench_nv_kernel_postopt_seedpass_20260217.json`), no codegen uplift on queried kernels | Reverted (no measured gain in repeated backend runs; did not beat kept A46 state) |
| A46 | 2026-02-17 | working tree | Split fill into `argon2id_fill_kernel` + `argon2id_fill_kernel_fused_target` (host dispatch by mode), seed rewrite to direct word emission (`blake2b_long_1024_words`), regcap frontier expansion with architecture-aware selection, autotune schema bump `7 -> 8` | preopt backend/kernel (`rreg=208`): `1.135/1.200 H/s` (`data/bench_nv_backend_preopt_20260217.json`, `data/bench_nv_kernel_preopt_20260217.json`); post-change backend/kernel (`rreg=208`): `1.139/1.200 H/s` (`data/bench_nv_backend_postopt_20260217.json`, `data/bench_nv_kernel_postopt_20260217.json`); regcap full reruns: `r192=1.141`, `r144=1.141`, `r96=1.137` (`data/bench_nv_backend_postopt_r192_20260217.json`, `data/bench_nv_backend_postopt_r144_20260217.json`, `data/bench_nv_backend_postopt_r96_20260217.json`); fused rerun (`r208`) `1.125 H/s` (`data/bench_nv_backend_fused_postopt_20260217.json`) | Kept (small but repeatable backend gain, no kernel regression, materially better generated code quality for the non-fused hot loop and reduced seed stack pressure) |
| A45 | 2026-02-14 | working tree | Seed/eval launch-size probe: `SEED_KERNEL_THREADS/EVAL_KERNEL_THREADS` `64 -> 32` (host + CUDA constants) | candidates `1.509/1.461/1.459 H/s` (`data/bench_nv_backend_candidate_seed32_eval32_a_20260214.json`, `data/bench_nv_backend_candidate_seed32_eval32_b_20260214.json`, `data/bench_nv_backend_candidate_seed32_eval32_c_20260214.json`) vs controls `1.463/1.473/1.409 H/s` (`data/bench_nv_backend_ab_c64_a_20260214.json`, `data/bench_nv_backend_ab_c64_b_20260214.json`, `data/bench_nv_backend_control_seed64_eval64_c_20260214.json`) | Reverted (results were inconsistent/inconclusive under host-load variance; no reliable improvement over kept `64/64`) |
| A44 | 2026-02-14 | working tree | Re-test cancel-check interval `64 -> 96` under cleaner A/B runs (`20s` rounds, interleaved `96/64/96/64`) | `96` samples `1.468/1.452 H/s` (`data/bench_nv_backend_ab_c96_a_20260214.json`, `data/bench_nv_backend_ab_c96_b_20260214.json`) vs `64` samples `1.463/1.473 H/s` (`data/bench_nv_backend_ab_c64_a_20260214.json`, `data/bench_nv_backend_ab_c64_b_20260214.json`), plus earlier short-window probes `1.477/1.525/1.442` (`data/bench_nv_backend_candidate_cancel96_20260214.json`, `data/bench_nv_backend_candidate_cancel96_rerun_20260214.json`, `data/bench_nv_backend_candidate_cancel96_rerun2_20260214.json`) | Reverted (no stable gain; controlled 20s A/B slightly favored `64`) |
| A43 | 2026-02-14 | working tree | Deadline-tail batch-size clamp using per-assignment hash-time EMA (`hashes_per_batch` capped by remaining `stop_at` budget) | fixed `--nvidia-max-rregcount 224 --nvidia-hashes-per-launch-per-lane 2`: candidates `1.395/1.340 H/s` (`data/bench_nv_backend_candidate_tailclamp_20260214.json`, `data/bench_nv_backend_candidate_tailclamp_rerun_20260214.json`) with lower late share (`20.00%`/`18.18%`) | Reverted (reduced late work but clear throughput regression) |
| A42 | 2026-02-14 | working tree | Inner-loop shared `prev_block` cache rewrite in `argon2id_fill_kernel` (`compress_block_coop` extended with `next_rhs`, remove per-iter shared zeroing, reuse cached `rhs` for data-dependent `rand64`) | fixed `--nvidia-max-rregcount 224 --nvidia-hashes-per-launch-per-lane 2`: baseline kernel/backend `1.600/1.444 H/s` (`data/bench_nv_kernel_baseline_20260214_prevcache.json`, `data/bench_nv_backend_baseline_20260214_prevcache.json`); candidates kernel/backend `1.600/1.409` and backend rerun `1.408 H/s` (`data/bench_nv_kernel_candidate_20260214_prevcache.json`, `data/bench_nv_backend_candidate_20260214_prevcache.json`, `data/bench_nv_backend_candidate_rerun_20260214_prevcache.json`) | Reverted (kernel parity but backend regression `-2.42%` to `-2.49%`) |
| A41 | 2026-02-14 | working tree | Over-reduce cancel-check frequency: `CANCEL_CHECK_BLOCK_INTERVAL` `64 -> 128` | candidate `1.461 H/s` (`/tmp/seine-candidate-cancel128-backend-d2.json`) vs `32` baseline `1.480 H/s` (`/tmp/seine-baseline-backend-d2.json`) and `64` candidate `1.499 H/s` | Reverted (`-1.28%` vs baseline, and clearly below the `64` candidate) |
| A40 | 2026-02-14 | working tree | Raise in-kernel cancel checkpoint interval `CANCEL_CHECK_BLOCK_INTERVAL` `32 -> 64` to reduce control-check overhead in the Argon2 inner block loop | backend baseline `1.480 H/s` (`/tmp/seine-baseline-backend-d2.json`), candidates `1.499/1.494 H/s` (`/tmp/seine-candidate-cancel64-backend-d2.json`, `/tmp/seine-candidate-cancel64-backend-d2-rerun.json`); kernel parity `1.600 H/s` (`/tmp/seine-candidate-cancel64-kernel-d2.json`) | Kept (repeatable backend uplift `+0.95%` to `+1.28%` with unchanged `late_hash_pct=25%` and no kernel regression) |
| A39 | 2026-02-14 | working tree | Launch-depth sanity sweep with fixed `--nvidia-max-rregcount 224`: compare `--nvidia-hashes-per-launch-per-lane` `2/3/4` under the same 3-round backend benchmark | depth-2 baseline `1.480 H/s` (`/tmp/seine-baseline-backend-d2.json`), depth-3 `1.471 H/s` (`/tmp/seine-probe-backend-d3.json`), depth-4 `1.474 H/s` + `late_hash_pct=50%` (`/tmp/seine-probe-backend-d4.json`) | Kept depth-2 as operational default for this profile (higher static depth regressed counted H/s and/or increased late-work share) |
| A38 | 2026-02-14 | working tree | Retune adaptive-pressure dynamics: `ADAPTIVE_DEPTH_PRESSURE_CONTROL_BONUS 4 -> 2`, `ADAPTIVE_DEPTH_PRESSURE_REPLACE_BONUS 2 -> 1` (same ratio, faster effective decay) | baseline `1.422 H/s` (`/tmp/seine-next-baseline-cancelpath.json`); candidates `1.512/1.517 H/s` (`/tmp/seine-next-candidate-pressureconstants.json`, `/tmp/seine-next-candidate-pressureconstants-rerun.json`); kernel parity `1.600 H/s` (`/tmp/seine-next-candidate-pressureconstants-kernel.json`) | Kept (repeatable backend uplift `+6.34%` to `+6.71%` with unchanged `late_hash_pct=25%`; no kernel regression) |
| A37 | 2026-02-14 | working tree | Idle-phase adaptive-pressure resets on assign/cancel/fence when no active/queued work | baseline `1.422 H/s` (`/tmp/seine-next-baseline-cancelpath.json`); candidate `1.411 H/s` (`/tmp/seine-next-candidate-idlereset.json`) | Reverted (`-0.78%`, no late-hash improvement) |
| A36 | 2026-02-14 | working tree | Immediate cancel-path CUDA interrupt on every regular `cancel` request (not only timeout interrupts) | baseline `1.422 H/s` (`/tmp/seine-next-baseline-cancelpath.json`); candidates `1.419/1.347 H/s` (`/tmp/seine-next-candidate-cancelpath.json`, `/tmp/seine-next-candidate-cancelpath-rerun.json`) | Reverted (first run near-flat `-0.25%`, rerun `-5.31%`; extra cancel signaling added instability/regression in this environment) |
| A35 | 2026-02-14 | working tree | Adaptive launch-depth pressure accounting fix: only add replace/cancel/fence pressure when commands preempt active/queued work (idle round-boundary control no longer ratchets pressure) | same-machine fixed `--nvidia-max-rregcount 224 --nvidia-hashes-per-launch-per-lane 2`: control `1.406 H/s` (`/tmp/seine-probe-backend-rreg224-currentstate.json`), candidate reruns `1.421/1.417/1.410 H/s` (`/tmp/seine-candidate-backend-pressurefix.json`, `/tmp/seine-candidate-backend-pressurefix-rerun.json`, `/tmp/seine-candidate-backend-pressurefix-vsbaseline.json`) | Kept (small but consistent uplift in low-clock control-pressure scenarios: `+0.29%` to `+1.08%`; avoids false depth throttling after idle cancel/fence bookkeeping) |
| A34 | 2026-02-14 | working tree | NVIDIA worker adaptive launch-depth rewrite: add per-assignment hash-time EMA and deadline-headroom depth trimming near `stop_at` (no lane throttling, max depth still operator-controlled) | fixed `--nvidia-max-rregcount 224 --nvidia-hashes-per-launch-per-lane 2`: prior sample `1.441 H/s` (`/tmp/seine-probe-backend-fixed224-d2-afterd1.json`), candidate `1.521 H/s` (`/tmp/seine-candidate-backend-depthshape-d2-rerun.json`); control run with `--nvidia-no-adaptive-launch-depth` in same code `1.501 H/s` with `late_hash_pct=50%` (`/tmp/seine-candidate-backend-depthshape-d2-noadaptive-rerun.json`) | Kept (backend avg `+5.58%` vs prior sample and `+1.36%` vs non-adaptive control while holding `late_hash_pct=25%`; kernel throughput unchanged at `1.600 H/s`) |
| A33 | 2026-02-14 | working tree | NVIDIA policy/config surface + optional fused in-kernel target evaluation + finer in-kernel cancel checkpoints + autotune schema bump `6 -> 7` with deadline-aware counted-H/s scoring and expanded depth candidates | backend validation on RTX 3080 (fixed `--nvidia-max-rregcount 224 --nvidia-hashes-per-launch-per-lane 2`): separate eval path `1.559 H/s` (`/tmp/nv-reg224-d2-long.json`), fused path `1.480 H/s` (`/tmp/nv-postchange-backend-long.json`), strict separate path `1.518 H/s` (`/tmp/nv-reg224-d2-long-strict.json`) | Kept with fused default OFF (control responsiveness improved under stale/cancel pressure and autotune now optimizes deadline-window effective work; fused path retained as experimental knob) |
| A32 | 2026-02-14 | working tree | GPU-side seed and solution evaluation pipeline (`build_seed_blocks_kernel` + `evaluate_hashes_kernel`), worker loop migrated to GPU-found nonce path, pinned lane hint across starts, autotune key/schema update (`4 -> 5`) with memory-budget bucketing + lane-capacity tier | final validation reruns: kernel `1.600 H/s` (`/tmp/nv-final-kernel-20260214.log`), backend `1.532 H/s` (`/tmp/nv-final-backend-20260214.log`) | Kept (backend uplift vs prior best `1.503 H/s` is `+1.93%`, stable 3-round kernel parity, and removes host-side hashing overhead + cache-key churn) |
| A31 | 2026-02-14 | working tree | Multi-hash-per-launch path + increase default `nvidia_hashes_per_launch_per_lane` `1 -> 2` | baseline default(1) backend `1.386/1.330 H/s`; depth-2 runs `1.459/1.455 H/s`; final default-state validation `1.503 H/s` | Kept (higher counted throughput on RTX 3080; baseline-mean `1.358` -> final `1.503` (`+10.68%`); tradeoff: late-hash share increased from `25%` to `42.86-50.00%`, keep CLI override for finer preemption) |
| A30 | 2026-02-14 | working tree | NVIDIA tuning surface expansion (`--nvidia-max-rregcount`, `--nvidia-max-lanes`, `--nvidia-dispatch-iters-per-lane`, `--nvidia-allocation-iters-per-lane`, `--nvidia-autotune-samples`), autotune schema bump `3 -> 4`, key update (`memory_budget_mib`), per-candidate multi-sample median scoring | validation reruns (before launch-depth default switch): kernel `1.600 H/s` (`/tmp/nv-final-kernel.log`), backend `1.386 H/s` (`/tmp/nv-final-backend.log`) | Kept (robust autotune cache identity + lower tuning variance; no correctness/runtime regressions) |
| A29 | 2026-02-14 | working tree | Warp-utilization rewrite in `compress_block_coop` (`tid<8` phases -> full-warp cooperative state mapping) | baseline: kernel `1.032 H/s`, backend `1.056 H/s`; candidates: kernel `1.282/1.220 H/s`, backend `1.105/1.207 H/s` | Kept (kernel mean `+21.22%`; backend mean `+9.47%`; clear sustained uplift) |
| A28 | 2026-02-14 | working tree | Little-endian memcpy fast path for seed-word expansion + final block byte packing | kernel `1.136 H/s` vs local kept-state `1.117 H/s`; backend `1.167 H/s` vs local kept-state `1.171 H/s` | Reverted (backend delta `-0.34%`, below keep gate and negative) |
| A27 | 2026-02-14 | working tree | Deadline-tail dynamic lane throttling via per-assignment hash-time EMA | kernel candidate `0.881 H/s`; backend candidate `0.880 H/s` vs same-pass baseline `0.964/1.045 H/s` | Reverted (clear throughput regression; reduced late shares but hurt total H/s) |
| A26 | 2026-02-14 | working tree | True NVIDIA batch queueing (no collapse), free-VRAM-aware lane budgeting (`derive_memory_budget_mib`), autotune key/schema update (`schema=3`, include compute capability) | fresh baseline: kernel `0.964 H/s`, backend `1.045 H/s`; clean kernel candidates `1.149/1.117/1.155 H/s`; backend candidates `1.183/1.171/1.164 H/s` (additional low-clock samples `1.044/1.044 H/s`) | Kept (kernel mean `+18.29%`; backend mean `+7.29%` across all clean samples; queueing correctness + OOM resilience improved) |
| A25 | 2026-02-14 | working tree | Remove live `SEINE_BLOCK_LOOP_UNROLL` NVRTC/kernel path; keep cache compatibility (`schema=2`, `#[serde(default)] block_loop_unroll`) and unroll candidate disabled | kernel reruns with fixed regcap `160`: `1.163/1.201 H/s` vs `HEAD` `1.184 H/s`; backend rerun `1.279 H/s` vs `HEAD` `1.213 H/s` | Kept (kernel best `+1.44%`; backend best `+5.44%`; avoids forced cache-rebuild churn) |
| A24 | 2026-02-14 | working tree | Keep worker channel split + nonblocking control path; revert deadline-tail lane throttling | backend reruns with fixed regcap `160`: `1.195/1.248 H/s` vs `HEAD` `1.213 H/s` | Kept (`+2.89%` best-vs-baseline; control enqueue no longer blocks behind long kernel batches) |
| A23 | 2026-02-14 | working tree | Split NVIDIA worker channels (`assign` vs `control`), enable true nonblocking backend calls, and initially add deadline-tail lane throttling plus loop-unroll autotune candidate | same-machine `HEAD` baseline (fixed regcap `160`): kernel `1.184 H/s`, backend `1.213 H/s`; initial candidate: kernel `1.119 H/s`, backend `1.049 H/s` | Partially reverted (tail throttling + active unroll path regressed throughput) |
| A22 | 2026-02-13 | working tree | Drop NVRTC option `--use_fast_math` from NVIDIA kernel compile flags | baseline `1.138 H/s`; candidates `1.114/1.130 H/s`; final rerun `1.121 H/s` | Reverted (`-0.70%` best-vs-baseline, below keep gate and negative) |
| A21 | 2026-02-13 | working tree | Add NVRTC PTXAS cache hint `--ptxas-options=-dlcm=cg` | baseline `1.139 H/s`; candidates `1.045/1.048 H/s`; final rerun `1.138 H/s` | Reverted (`-7.99%` best-vs-baseline, clear and stable regression) |
| A20 | 2026-02-13 | working tree | NVIDIA autotune schema bump `2 -> 3` + regcap candidate sweep `240/224/208/192/176/160/144` | baseline `1.143 H/s`; candidates `0.864/1.143 H/s`; final reruns `0.874/1.122 H/s` | Reverted (best delta `0.00%`, below `0.5%` keep gate; introduced one-time cache-rebuild outlier) |
| A19 | 2026-02-13 | working tree | Drop NVRTC option `--extra-device-vectorization` from NVIDIA kernel compile flags | baseline `1.094 H/s`; candidates `1.179/1.193 H/s`; final rerun `1.193 H/s` | Kept (`+9.05%` best-vs-baseline, `+8.41%` mean, stable across rerun) |
| A18 | 2026-02-13 | working tree | NVIDIA autotune schema bump `1 -> 2` + regcap candidate sweep `240/224/208/192/160` | baseline `1.162 H/s`; candidates `0.896/1.202 H/s`; final rerun `1.208 H/s` | Kept (`+3.44%` best-vs-baseline; first candidate outlier tied to one-time cache rebuild) |
| A17 | 2026-02-13 | working tree | Compile-time Argon2 constants via NVRTC defines (`SEINE_FIXED_M_BLOCKS`, `SEINE_FIXED_T_COST`) | `1.214 H/s` avg | Kept (new best, stable over rerun) |
| A16 | 2026-02-13 | working tree | Direct compression write-to-destination (drop `block_tmp` shared staging) | `1.120 H/s` avg | Kept (clear uplift over baseline) |
| A15 | 2026-02-13 | working tree | Remove post-store `coop_sync()` in inner block loop | `1.014 H/s` avg | Reverted (regressed vs 1.026 baseline) |
| A14 | 2026-02-13 | working tree | Keep warp-sync + drop device hash-counter + restore per-thread ref-index + remove pre-D2H stream sync | `1.027 H/s` avg | Kept (new best, stable over rerun) |
| A13 | 2026-02-13 | working tree | Warp-sync + device hash-counter removal + lane-0 ref-index broadcast | `0.977 H/s` avg | Reverted (slower than baseline) |
| A12 | 2026-02-13 | working tree | Cooperative loop unroll pragma pass | `0.583 H/s` | Reverted |
| A11 | 2026-02-13 | working tree | Thread-0-only ref-index mapping micro-opt | `0.849 H/s` avg | Reverted |
| A10 | 2026-02-13 | working tree | PTXAS cache hint `-dlcm=ca` | `0.985 H/s` avg | Reverted |
| A09 | 2026-02-13 | working tree | Regcap A/B: `224` vs `160` | `1.007` vs `0.973 H/s` avg | `224` kept |
| A08 | 2026-02-13 | working tree | Lane cap sweep: `1/2/3/4` | `0.246/0.487/0.736/0.957 H/s` | Highest lane count kept |
| A07 | 2026-02-13 | working tree | Cooperative threads sweep: `24/32/40/48` | `0.574/0.978/0.590/0.766 H/s` | `32` kept |
| A06 | 2026-02-13 | `1198bd2` | Cooperative per-lane kernel rewrite | `0.983 H/s` avg | Kept |
| A05 | 2026-02-13 | pre-`35190c1` | VRAM touch-probe + lane backoff + regcap tuning | up to `0.128 H/s` | Kept in `35190c1` |
| A04 | 2026-02-13 | pre-`35190c1` | Shared-memory scratch rewrite (old kernel) | `0.050 H/s` | Reverted |
| A03 | 2026-02-13 | pre-`35190c1` | Full free-VRAM lane sizing without probe | OOM at startup | Reverted |
| A02 | 2026-02-13 | pre-`35190c1` | One lane per CUDA block launch geometry | `0.076 H/s` | Kept |
| A01 | 2026-02-13 | `2b5ed78` | Initial native CUDA backend | `0.065 H/s` | Baseline |

## New entry template

Copy this row and fill every field after each pass:

`| YYYY-MM-DD | <commit or working tree> | <exact code/config change> | <benchmark reports + averaged H/s> | <Kept/Reverted + rationale> |`
